{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eExHrdNL0GNS",
    "colab_type": "text"
   },
   "source": [
    "## Tensorflow + RNN 을 활용한 영화 리뷰 감성 분석\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2bdeJlB0_BP",
    "colab_type": "text"
   },
   "source": [
    "#### (1) 전처리 된 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "edD7aGI6pZiq",
    "colab_type": "code",
    "outputId": "5f41d95a-a586-4844-fcf7-9518922a73dc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.573580419104E12,
     "user_tz": -540.0,
     "elapsed": 1032.0,
     "user": {
      "displayName": "GyuWon Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC2i-XV_1q37sR-tiwIOEBODzdJWg6BkfIPMUK0uA=s64",
      "userId": "14874574060895645490"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "aLdUjCrU-gWG",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/content/drive/My Drive/Colab Notebooks/preprocessed_data.pkl\", \"rb\") as f:\n",
    "  saved_data = pickle.load(f)\n",
    "  \n",
    "word2idx = saved_data[\"word2idx\"]\n",
    "embedding_matrix = saved_data[\"embedding_matrix\"]\n",
    "\n",
    "train_sents = saved_data[\"train_sents\"]\n",
    "test_sents = saved_data[\"test_sents\"]\n",
    "\n",
    "train_labels = saved_data[\"train_labels\"]\n",
    "test_labels = saved_data[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-l2yyyDsT54c",
    "colab_type": "text"
   },
   "source": [
    "#### (2) 인풋 데이터 형태 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IilanbzyAhwO",
    "colab_type": "code",
    "outputId": "bcb76135-8da1-4661-b333-eff32ad4bd10",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.573580422089E12,
     "user_tz": -540.0,
     "elapsed": 3997.0,
     "user": {
      "displayName": "GyuWon Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC2i-XV_1q37sR-tiwIOEBODzdJWg6BkfIPMUK0uA=s64",
      "userId": "14874574060895645490"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(1109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "xQlEfU05Va-d",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# train_data 에서 랜덤하게 10% 를 검증 데이터로 구성\n",
    " train_sents, val_sents, train_labels, val_labels = train_test_split(train_sents, train_labels, test_size=0.1, random_state=1109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CF9ED8rDV8_d",
    "colab_type": "code",
    "outputId": "d0e86c77-cabe-4030-f1c4-8e08fced8fd2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.573580422416E12,
     "user_tz": -540.0,
     "elapsed": 4308.0,
     "user": {
      "displayName": "GyuWon Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC2i-XV_1q37sR-tiwIOEBODzdJWg6BkfIPMUK0uA=s64",
      "userId": "14874574060895645490"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134995"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fC54cNHfV_Sy",
    "colab_type": "code",
    "outputId": "d7404713-94ff-4941-b2b4-6debcb8ba6cd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.573580422418E12,
     "user_tz": -540.0,
     "elapsed": 4302.0,
     "user": {
      "displayName": "GyuWon Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC2i-XV_1q37sR-tiwIOEBODzdJWg6BkfIPMUK0uA=s64",
      "userId": "14874574060895645490"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "93M8Zo75WIki",
    "colab_type": "code",
    "outputId": "a7491441-7cb0-4cc2-8fe6-0a44f0696091",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.573580422419E12,
     "user_tz": -540.0,
     "elapsed": 4294.0,
     "user": {
      "displayName": "GyuWon Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC2i-XV_1q37sR-tiwIOEBODzdJWg6BkfIPMUK0uA=s64",
      "userId": "14874574060895645490"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49997"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "QXGfb1zlT32l",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# train_sents, val_sents 를 word2idx 를 사용해서 각 단어별 index 값을 가지는 numpy array 형태로 구축\n",
    "# 전체 데이터에 대해서 train_data 의 max_length 기준으로 padding 진행\n",
    "\n",
    "max_length = max([len(sent) for sent in train_sents])\n",
    "train_seqs = []\n",
    "val_seqs = []\n",
    "\n",
    "for sent in train_sents:\n",
    "  tmp = np.zeros(max_length, dtype=\"int32\")\n",
    "  for i, word in enumerate(sent):\n",
    "    idx = word2idx.get(word)\n",
    "    if idx != None:\n",
    "      tmp[i] = idx\n",
    "    else:\n",
    "      tmp[i] = word2idx.get(\"<UNK>\") # out of vocab word 처리\n",
    "  train_seqs.append(tmp)\n",
    "\n",
    "for sent in val_sents:\n",
    "  tmp = np.zeros(max_length, dtype=\"int32\")\n",
    "  for i, word in enumerate(sent):\n",
    "    idx = word2idx.get(word)\n",
    "    if idx != None:\n",
    "      tmp[i] = idx\n",
    "    else:\n",
    "      tmp[i] = word2idx.get(\"<UNK>\")\n",
    "  val_seqs.append(tmp)\n",
    "\n",
    "train_inputs = np.stack(train_seqs)\n",
    "val_inputs = np.stack(val_seqs)\n",
    "train_targets = np.array(train_labels, dtype=\"int32\")\n",
    "val_targets = np.array(val_labels, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mHzGglo0aKUM",
    "colab_type": "code",
    "outputId": "cbeff016-2b26-4bab-aa29-7ecf97d8cc57",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.573580425053E12,
     "user_tz": -540.0,
     "elapsed": 6910.0,
     "user": {
      "displayName": "GyuWon Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC2i-XV_1q37sR-tiwIOEBODzdJWg6BkfIPMUK0uA=s64",
      "userId": "14874574060895645490"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134995, 116)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "l0rJOC_HaM9S",
    "colab_type": "code",
    "outputId": "5a23aec4-1562-46a7-e1ad-51d37275d604",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.573580425054E12,
     "user_tz": -540.0,
     "elapsed": 6904.0,
     "user": {
      "displayName": "GyuWon Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC2i-XV_1q37sR-tiwIOEBODzdJWg6BkfIPMUK0uA=s64",
      "userId": "14874574060895645490"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 116)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mtAtvlhkagAp",
    "colab_type": "code",
    "outputId": "7f1b3f03-af2f-4a4c-8a78-d3b43587d3d1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.573580425055E12,
     "user_tz": -540.0,
     "elapsed": 6894.0,
     "user": {
      "displayName": "GyuWon Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC2i-XV_1q37sR-tiwIOEBODzdJWg6BkfIPMUK0uA=s64",
      "userId": "14874574060895645490"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 423,  256, 4860,   17,  312,  989,   37,  157,   47, 1107,   97,\n",
       "         58,   59, 1966,   37,    5,   13,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "r98uC2iUa5zR",
    "colab_type": "code",
    "outputId": "740c8f4f-5f0a-49be-c34e-574637a83d17",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.573580425056E12,
     "user_tz": -540.0,
     "elapsed": 6886.0,
     "user": {
      "displayName": "GyuWon Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC2i-XV_1q37sR-tiwIOEBODzdJWg6BkfIPMUK0uA=s64",
      "userId": "14874574060895645490"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3GYJB4F2UXf",
    "colab_type": "text"
   },
   "source": [
    "#### (3) 텐서플로우 모델 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FvDelCT2ml2",
    "colab_type": "text"
   },
   "source": [
    "#### -- (i) 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "VAWTVYOQbIbp",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 512\n",
    "learning_rate = 0.01\n",
    "vocab_size = len(word2idx)\n",
    "embedding_size = 100\n",
    "hidden_size = 64\n",
    "max_length = train_inputs.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZNMpV033RqH",
    "colab_type": "text"
   },
   "source": [
    "#### -- (ii) 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "g_0-lsD7P1rG",
    "colab_type": "code",
    "outputId": "1eb367f7-52c9-470e-8f7b-fc6839230ae8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.57358042546E12,
     "user_tz": -540.0,
     "elapsed": 7275.0,
     "user": {
      "displayName": "GyuWon Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC2i-XV_1q37sR-tiwIOEBODzdJWg6BkfIPMUK0uA=s64",
      "userId": "14874574060895645490"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         6125100   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, None, 64)          42496     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                33280     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,200,941\n",
      "Trainable params: 75,841\n",
      "Non-trainable params: 6,125,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim = vocab_size,\n",
    "                           output_dim = embedding_size,\n",
    "                           embeddings_initializer = Constant(embedding_matrix),\n",
    "                           trainable = False))\n",
    "\n",
    "# stacked RNN 사용시, 가장 마지막 layer 를 제외하고는 return sequences 를 입력해주어야 함\n",
    "model.add(layers.CuDNNLSTM(units=hidden_size, return_sequences=True, input_shape=(max_length, embedding_size)))\n",
    "model.add(layers.CuDNNLSTM(units=hidden_size))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-x8h-E0C-9b",
    "colab_type": "text"
   },
   "source": [
    "#### -- (iii) 모델 학습 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "v2acjaXTc1Qq",
    "colab_type": "code",
    "outputId": "430a7594-59e2-4ef5-ce29-6e84ef46e81a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.573580858978E12,
     "user_tz": -540.0,
     "elapsed": 440786.0,
     "user": {
      "displayName": "GyuWon Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC2i-XV_1q37sR-tiwIOEBODzdJWg6BkfIPMUK0uA=s64",
      "userId": "14874574060895645490"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 134995 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "134995/134995 [==============================] - 16s 117us/sample - loss: 0.6934 - acc: 0.5018 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 2/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6933 - acc: 0.4987 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 3/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6932 - acc: 0.4973 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 4/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6932 - acc: 0.5006 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 5/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6932 - acc: 0.4991 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 6/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 7/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6932 - acc: 0.4984 - val_loss: 0.6932 - val_acc: 0.4969\n",
      "Epoch 8/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6932 - acc: 0.5024 - val_loss: 0.6932 - val_acc: 0.4969\n",
      "Epoch 9/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6932 - val_acc: 0.4969\n",
      "Epoch 10/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6932 - acc: 0.4989 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 11/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.5031\n",
      "Epoch 12/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6932 - acc: 0.5008 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 13/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6932 - acc: 0.4985 - val_loss: 0.6932 - val_acc: 0.4969\n",
      "Epoch 14/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.6933 - acc: 0.5013 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 15/30\n",
      "134995/134995 [==============================] - 14s 105us/sample - loss: 0.6932 - acc: 0.4975 - val_loss: 0.6932 - val_acc: 0.4969\n",
      "Epoch 16/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.5892 - acc: 0.6391 - val_loss: 0.4471 - val_acc: 0.7978\n",
      "Epoch 17/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.3967 - acc: 0.8238 - val_loss: 0.3878 - val_acc: 0.8257\n",
      "Epoch 18/30\n",
      "134995/134995 [==============================] - 14s 107us/sample - loss: 0.3512 - acc: 0.8455 - val_loss: 0.3629 - val_acc: 0.8399\n",
      "Epoch 19/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.3296 - acc: 0.8565 - val_loss: 0.3456 - val_acc: 0.8495\n",
      "Epoch 20/30\n",
      "134995/134995 [==============================] - 14s 107us/sample - loss: 0.3153 - acc: 0.8639 - val_loss: 0.3440 - val_acc: 0.8495\n",
      "Epoch 21/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.3032 - acc: 0.8691 - val_loss: 0.3416 - val_acc: 0.8499\n",
      "Epoch 22/30\n",
      "134995/134995 [==============================] - 14s 107us/sample - loss: 0.2932 - acc: 0.8747 - val_loss: 0.3366 - val_acc: 0.8527\n",
      "Epoch 23/30\n",
      "134995/134995 [==============================] - 14s 107us/sample - loss: 0.2850 - acc: 0.8784 - val_loss: 0.3364 - val_acc: 0.8528\n",
      "Epoch 24/30\n",
      "134995/134995 [==============================] - 14s 107us/sample - loss: 0.2760 - acc: 0.8832 - val_loss: 0.3391 - val_acc: 0.8513\n",
      "Epoch 25/30\n",
      "134995/134995 [==============================] - 14s 107us/sample - loss: 0.2688 - acc: 0.8868 - val_loss: 0.3440 - val_acc: 0.8493\n",
      "Epoch 26/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.2610 - acc: 0.8901 - val_loss: 0.3437 - val_acc: 0.8523\n",
      "Epoch 27/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.2559 - acc: 0.8929 - val_loss: 0.3450 - val_acc: 0.8511\n",
      "Epoch 28/30\n",
      "134995/134995 [==============================] - 14s 107us/sample - loss: 0.2505 - acc: 0.8956 - val_loss: 0.3463 - val_acc: 0.8508\n",
      "Epoch 29/30\n",
      "134995/134995 [==============================] - 14s 107us/sample - loss: 0.2420 - acc: 0.8996 - val_loss: 0.3527 - val_acc: 0.8528\n",
      "Epoch 30/30\n",
      "134995/134995 [==============================] - 14s 106us/sample - loss: 0.2374 - acc: 0.9020 - val_loss: 0.3465 - val_acc: 0.8508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdaf2f5cf98>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=adam,\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_inputs, train_targets, epochs=epochs,\n",
    "          batch_size=batch_size, validation_data=(val_inputs, val_targets))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "(4) SA-w2v-train-CuDNNLSTM-stacked.ipynb",
   "provenance": [
    {
     "file_id": "1edafAptDeoQpGQwUVaisrGombudnV6TR",
     "timestamp": 1.573579759532E12
    },
    {
     "file_id": "1Jdak8bu0hOQhDnIrzFHLzzEfx5DRjR_x",
     "timestamp": 1.573578808473E12
    }
   ],
   "collapsed_sections": [
    "F3GYJB4F2UXf"
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
