{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eExHrdNL0GNS",
    "colab_type": "text"
   },
   "source": [
    "## Tensorflow + RNN 을 활용한 영화 리뷰 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2bdeJlB0_BP",
    "colab_type": "text"
   },
   "source": [
    "#### (1) 드라이브 마운트 및 mecab 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "edD7aGI6pZiq",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "74swAKOwGvcB",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "! wget --no-check-certificate https://raw.github.com/SOMJANG/Mecab-ko-for-Google-Colab/master/install_mecab-ko_on_colab190912.sh\n",
    "!bash install_mecab-ko_on_colab190912.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v95eROg2QfSb",
    "colab_type": "text"
   },
   "source": [
    "#### (2) 필요 모듈 임포트, 전처리 된 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "me-2GhCYQenX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "tf.set_random_seed(1109)\n",
    "mecab = Mecab()\n",
    "\n",
    "with open(\"/content/drive/My Drive/Colab Notebooks/preprocessed_data.pkl\", \"rb\") as f:\n",
    "  saved_data = pickle.load(f)\n",
    "  \n",
    "word2idx = saved_data[\"word2idx\"]\n",
    "embedding_matrix = saved_data[\"embedding_matrix\"]\n",
    "\n",
    "train_sents = saved_data[\"train_sents\"]\n",
    "test_sents = saved_data[\"test_sents\"]\n",
    "\n",
    "train_labels = saved_data[\"train_labels\"]\n",
    "test_labels = saved_data[\"test_labels\"]\n",
    "\n",
    "# train_data 에서 랜덤하게 10% 를 검증 데이터로 구성\n",
    "train_sents, val_sents, train_labels, val_labels = train_test_split(train_sents, train_labels, test_size=0.1, random_state=1109)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-l2yyyDsT54c",
    "colab_type": "text"
   },
   "source": [
    "#### (2) 토크나이저 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "VL1x5kpyHLNK",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def tokenizer(sent):\n",
    "  res = []\n",
    "  tmp = mecab.pos(sent)\n",
    "  tmp = list(map(lambda x: x[0]+\"/\"+x[1], tmp))\n",
    "  for i, word in enumerate(tmp):\n",
    "    idx = word2idx.get(word)\n",
    "    if idx != None:\n",
    "      res.append(idx)\n",
    "    else:\n",
    "      res.append(word2idx.get(\"<UNK>\")) # out of vocab word 처리\n",
    "\n",
    "  return np.array([res], dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3GYJB4F2UXf",
    "colab_type": "text"
   },
   "source": [
    "#### (3) 인풋 데이터 형태로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "da9Cp8OrRo5u",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# train_sents, val_sents 를 word2idx 를 사용해서 각 단어별 index 값을 가지는 numpy array 형태로 구축\n",
    "# 전체 데이터에 대해서 train_data 의 max_length 기준으로 padding 진행\n",
    "\n",
    "max_length = max([len(sent) for sent in train_sents])\n",
    "train_seqs = []\n",
    "val_seqs = []\n",
    "test_seqs = []\n",
    "\n",
    "for sent in train_sents:\n",
    "  tmp = np.zeros(max_length, dtype=\"int32\")\n",
    "  for i, word in enumerate(sent):\n",
    "    idx = word2idx.get(word)\n",
    "    if idx != None:\n",
    "      tmp[i] = idx\n",
    "    else:\n",
    "      tmp[i] = word2idx.get(\"<UNK>\") # out of vocab word 처리\n",
    "  train_seqs.append(tmp)\n",
    "\n",
    "for sent in val_sents:\n",
    "  tmp = np.zeros(max_length, dtype=\"int32\")\n",
    "  for i, word in enumerate(sent):\n",
    "    idx = word2idx.get(word)\n",
    "    if idx != None:\n",
    "      tmp[i] = idx\n",
    "    else:\n",
    "      tmp[i] = word2idx.get(\"<UNK>\")\n",
    "  val_seqs.append(tmp)\n",
    "\n",
    "for sent in test_sents:\n",
    "  tmp = np.zeros(max_length, dtype=\"int32\")\n",
    "  for i, word in enumerate(sent):\n",
    "    idx = word2idx.get(word)\n",
    "    if idx != None:\n",
    "      tmp[i] = idx\n",
    "    else:\n",
    "      tmp[i] = word2idx.get(\"<UNK>\")\n",
    "  test_seqs.append(tmp)\n",
    "\n",
    "\n",
    "train_inputs = np.stack(train_seqs)\n",
    "val_inputs = np.stack(val_seqs)\n",
    "test_inputs = np.stack(test_seqs)\n",
    "\n",
    "train_targets = np.array(train_labels, dtype=\"int32\")\n",
    "val_targets = np.array(val_labels, dtype=\"int32\")\n",
    "test_targets = np.array(test_labels, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-x8h-E0C-9b",
    "colab_type": "text"
   },
   "source": [
    "#### (4) 텐서플로우 모델 구축하기\n",
    "\n",
    "* 하이퍼파라미터는 자유롭게 설정\n",
    "* CuDNNGRU 사용, 3-layer stacked GRU, Bidirectional 사용\n",
    "* val_loss 기준으로 가장 성능이 좋은 모델을 best_model_GRU.h5 로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5UWiHoCSV7h",
    "colab_type": "text"
   },
   "source": [
    "#### -- (i) 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "oiXNIRimSbIN",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# 자유롭게 하이퍼파라미터를 수정해주세요~!!\n",
    "epochs = 10\n",
    "batch_size = 1024\n",
    "learning_rate = 0.01\n",
    "hidden_size = 32\n",
    "dropout = 0.3\n",
    "\n",
    "vocab_size = len(word2idx) # don't change\n",
    "embedding_size = 100 # don't change\n",
    "max_length = train_inputs.shape[1] # don't change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlI0fknPT1Bn",
    "colab_type": "text"
   },
   "source": [
    "#### -- (ii) 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Z87PkcLtSLgW",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim = vocab_size,\n",
    "                           output_dim = embedding_size,\n",
    "                           embeddings_initializer = Constant(embedding_matrix),\n",
    "                           trainable = False))\n",
    "\n",
    "# your code here\n",
    "# stacked RNN 사용시, 가장 마지막 layer 를 제외하고는 return sequences 를 입력해주어야 함\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOEVYs6rUBQW",
    "colab_type": "text"
   },
   "source": [
    "#### -- (iii) 모델 학습 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "6j9lTumRUGF0",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=adam,\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "saved_path = \"/content/drive/My Drive/Colab Notebooks/best_model_GRU.h5\"\n",
    "saved_dir = os.path.dirname(saved_path)\n",
    "\n",
    "# 가장 성능이 좋은 모델을 저장\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    saved_path, verbose=1, save_best_only=True, monitor=\"val_loss\")\n",
    "\n",
    "\n",
    "# your code here - fit() 안의 인자를 채워주세요 !!\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4g78Ra1U1d-",
    "colab_type": "text"
   },
   "source": [
    "#### (5) 학습된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "xmqJn6cpVVPH",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# your code here - pretrained_model 변수에 기존에 학습시킨 모델을 불러와서 넣어주세요 !!\n",
    "pretrained_model = \n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSrnJWCfVv1V",
    "colab_type": "text"
   },
   "source": [
    "#### (6) 테스트 데이터 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "EYNqyW9jVytE",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# your code here - pretrained_model.evaluate() 함수를 사용해서 테스트 데이터데 대한 평가를 진행해주세요.\n",
    "# pretrained_model.evaluate() 안의 인자를 채워주세요\n",
    "\n",
    "test_batch_size = 512\n",
    "pretrained_model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmtiL10sWSV_",
    "colab_type": "text"
   },
   "source": [
    "#### (7) 내가 만든 문장으로 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "v2acjaXTc1Qq",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# your code here - pos_sample 안에 내가 만든 긍정 문장을 넣어서 결과를 확인해보세요 !!\n",
    "\n",
    "pos_sample = \"\"\n",
    "pretrained_model.predict(tokenizer(pos_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "8ydfj-eJLXuZ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# your code here - neg_sample 안에 내가 만든 부정 문장을 넣어서 결과를 확인해보세요 !!\n",
    "\n",
    "neg_sample = \"\"\n",
    "pretrained_model.predict(tokenizer(neg_sample))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "(10) SA-practice.ipynb",
   "provenance": [
    {
     "file_id": "1RZysGs2xH8lVd5dqkAV8PnxpvXZjgmiS",
     "timestamp": 1.573593702933E12
    },
    {
     "file_id": "1r0CDlQpD7YZrKoDsiWgSf5617RPzq1ZB",
     "timestamp": 1.573589609083E12
    },
    {
     "file_id": "1Ia0QHs87RMb-31qeEAR70b8XKX6RFtL5",
     "timestamp": 1.573587050897E12
    },
    {
     "file_id": "1xDvDZpTsUMwQl4r0agwLw9WrMEqNPYbP",
     "timestamp": 1.573585210028E12
    },
    {
     "file_id": "1D7OGBTLX9z8VwuobC2X5CyEx048WOsgX",
     "timestamp": 1.573583655786E12
    },
    {
     "file_id": "1_BWSxpQvuETSXFKIR1WZvVvwpNJRmOcx",
     "timestamp": 1.573581569641E12
    },
    {
     "file_id": "1RLPK7VyzFnl4GBVnP1xY6NcO4_E9Hpsi",
     "timestamp": 1.573580891201E12
    },
    {
     "file_id": "1edafAptDeoQpGQwUVaisrGombudnV6TR",
     "timestamp": 1.573579759532E12
    },
    {
     "file_id": "1Jdak8bu0hOQhDnIrzFHLzzEfx5DRjR_x",
     "timestamp": 1.573578808473E12
    }
   ],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
